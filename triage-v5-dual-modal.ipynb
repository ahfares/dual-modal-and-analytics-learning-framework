{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "dataframe = pd.read_excel('triage dataset-coded 2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_symptoms = dataframe.loc[:, ['gender','age', 'job','respcontact','placevisit','healthworker','fever','cough','sorethroat','vomdiarrhea', 'malaise','smelltaste','smoking','pregnancy','immundiff','comorbid',\n",
    "    'dm',\n",
    "    'htn',\n",
    "    'cardiac',\n",
    "    'ckd',\n",
    "    'chest',\n",
    "    'hepatic',\n",
    "    'cancer',\n",
    "    'others']]\n",
    "selection_symptoms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "selection_symptoms_train_dataframe = train_dataframe.loc[:, ['gender','age', 'job','respcontact','placevisit','healthworker','fever','cough','sorethroat','vomdiarrhea', 'malaise','smelltaste','smoking','pregnancy','immundiff','comorbid',\n",
    "    'dm',\n",
    "    'htn',\n",
    "    'cardiac',\n",
    "    'ckd',\n",
    "    'chest',\n",
    "    'hepatic',\n",
    "    'cancer',\n",
    "    'others','pcr']]\n",
    "print(selection_symptoms_train_dataframe.shape)\n",
    "\n",
    "selection_lab_train_dataframe = train_dataframe.loc[:, ['wbc',\n",
    "    'neucount',\n",
    "    'neu',\n",
    "    'lymcount',\n",
    "    'lym',\n",
    "    'monocount',\n",
    "    'mono',\n",
    "    'eoscount',\n",
    "    'eos',\n",
    "    'basocount',\n",
    "    'baso',\n",
    "    'rbc',\n",
    "    'hgb',\n",
    "    'hct',\n",
    "    'mcv',\n",
    "    'mch',\n",
    "    'mchc',\n",
    "    'rdw',\n",
    "    'plt',\n",
    "    'mpv',\n",
    "    'neutolym',\n",
    "    'ast',\n",
    "    'alt',\n",
    "    'urea',\n",
    "    'creat',\n",
    "    'ldh',\n",
    "    'ck',\n",
    "    'crp',\n",
    "    'ferritin',\n",
    "    'inr','pcr']]\n",
    "\n",
    "print(selection_lab_train_dataframe.shape)\n",
    "\n",
    "# val\n",
    "\n",
    "selection_symptoms_val_dataframe = val_dataframe.loc[:, ['gender','age', 'job','respcontact','placevisit','healthworker','fever','cough','sorethroat','vomdiarrhea', 'malaise','smelltaste','smoking','pregnancy','immundiff','comorbid',\n",
    "    'dm',\n",
    "    'htn',\n",
    "    'cardiac',\n",
    "    'ckd',\n",
    "    'chest',\n",
    "    'hepatic',\n",
    "    'cancer',\n",
    "    'others','pcr']]\n",
    "print(selection_symptoms_val_dataframe.shape)\n",
    "\n",
    "selection_lab_val_dataframe = val_dataframe.loc[:, ['wbc',\n",
    "    'neucount',\n",
    "    'neu',\n",
    "    'lymcount',\n",
    "    'lym',\n",
    "    'monocount',\n",
    "    'mono',\n",
    "    'eoscount',\n",
    "    'eos',\n",
    "    'basocount',\n",
    "    'baso',\n",
    "    'rbc',\n",
    "    'hgb',\n",
    "    'hct',\n",
    "    'mcv',\n",
    "    'mch',\n",
    "    'mchc',\n",
    "    'rdw',\n",
    "    'plt',\n",
    "    'mpv',\n",
    "    'neutolym',\n",
    "    'ast',\n",
    "    'alt',\n",
    "    'urea',\n",
    "    'creat',\n",
    "    'ldh',\n",
    "    'ck',\n",
    "    'crp',\n",
    "    'ferritin',\n",
    "    'inr','pcr']]\n",
    "\n",
    "print(selection_lab_val_dataframe.shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"pcr\")\n",
    "    train_X=dataframe.values.tolist()\n",
    "    labels = labels.values.tolist()\n",
    "    return train_X,labels\n",
    "\n",
    "\n",
    "train_ds_1, y_1 = dataframe_to_dataset(selection_symptoms_train_dataframe)\n",
    "train_ds_2, y_2 = dataframe_to_dataset(selection_lab_train_dataframe)\n",
    "\n",
    "\n",
    "\n",
    "val_ds_1, y_1_v = dataframe_to_dataset(selection_symptoms_val_dataframe)\n",
    "val_ds_2, y_2_v = dataframe_to_dataset(selection_lab_val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1, y_1 = np.array(train_ds_1), np.array(y_1)\n",
    "train_ds_2, y_2 = np.array(train_ds_2), np.array(y_2)\n",
    "\n",
    "\n",
    "val_ds_1, y_1_v = np.array(val_ds_1), np.array(y_1_v)\n",
    "val_ds_2, y_2_v = np.array(val_ds_2), np.array(y_2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_string_categorical_feature(feature, name, dataset):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    index = StringLookup()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = index(feature)\n",
    "\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a dataset of indices\n",
    "    feature_ds = feature_ds.map(index)\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(encoded_feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_integer_categorical_feature(feature, name, dataset):\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_2.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "\n",
    "all_symptoms_inputs = keras.layers.Input(shape = train_ds_1.shape[-1])\n",
    "all_laboratory_inputs = keras.layers.Input(shape = train_ds_2.shape[-1])\n",
    "\n",
    "dense_1 = keras.layers.Dense(32)(all_symptoms_inputs)\n",
    "bn_1 = layers.BatchNormalization()(dense_1)\n",
    "lrelu_1 = layers.LeakyReLU()(bn_1)\n",
    "drop_1 = keras.layers.Dropout(0.5)(lrelu_1)\n",
    "flat1 = keras.layers.Flatten()(drop_1)\n",
    "\n",
    "\n",
    "dense_2 = keras.layers.Dense(32)(all_laboratory_inputs)\n",
    "bn_2 = layers.BatchNormalization()(dense_2)\n",
    "lrelu_2 = layers.LeakyReLU()(bn_2)\n",
    "drop_2 = keras.layers.Dropout(0.5)(lrelu_2)\n",
    "flat2 = keras.layers.Flatten()(drop_2)\n",
    "\n",
    "\n",
    "# merge input models\n",
    "x = keras.layers.Concatenate()([flat1, flat2])\n",
    "\n",
    "x = keras.layers.Dense(16)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(8)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model([all_symptoms_inputs, all_laboratory_inputs], output)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "#NAME = \"triage-v3\"\n",
    "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"triage_v4_dual_modal_weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit([train_ds_1, train_ds_2], y_1, validation_data=([val_ds_1, val_ds_2], y_1_v), epochs=100, batch_size=32, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('triage-v4-dual-modal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symptoms_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
